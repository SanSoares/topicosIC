In [1]:
#Equipe: Marianna Leandra, Nayara Thaiza, Samuel Soares
import numpy as np  
import matplotlib.pyplot as plt  
import pandas as pd  

#dados
from sklearn import datasets
#plot
import matplotlib.pyplot as plt

iris = datasets.load_iris()
X = iris.data[:, :3]  # as duas primeiras caracteristicas
y = iris.target #classificacao
#0 Comprimento da sépala; 1 Largura da sépala; 2 comprimento da pétala; Largura da pétala 
#setosa, versicolor, virginica

from sklearn.preprocessing import StandardScaler  
import numpy
scaler = StandardScaler()  
#dados de treinamento 'até 40' de cada classe
yt=numpy.concatenate([y[:40], y[51:90], y[101:140]])
xt = numpy.concatenate([X[:40,:], X[51:90,:], X[101:140,:]])
scaler.fit(xt, yt)  

#validacão com o restante dos dados
yv=numpy.concatenate([y[40:50], y[90:100], y[140:150]])
xv = numpy.concatenate([X[40:50,:], X[90:100,:], X[140:150,:]])

xt = scaler.transform(xt)  
xv = scaler.transform(xv)  

from sklearn.neighbors import KNeighborsClassifier  
classifier = KNeighborsClassifier(n_neighbors=5)  
classifier.fit(xt, yt)  

yp = classifier.predict(xv) 
print(yp)
print(yv)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2]
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]
In [2]:
#Etapa 2 -- Validacao
from sklearn.metrics import classification_report, confusion_matrix  
#print(confusion_matrix(yv, yp))  
#print(classification_report(yv, yp)) 
print(classifier.score(xv,yv))
0.9666666666666667
In [ ]:
#Com 2 caracteristicas e k = 1  temos aproximadamente 66% de acerto
#Com 2 caracteristicas e k = 3  temos aproximadamente 70% de acerto
#Com 2 características e k = 5 temos aproximadamente 73% de acerto
#Com 3 caracteristicas e k = 1  temos aproximadamente 83% de acerto
#Com 3 caracteristicas e k = 3  temos aproximadamente 90% de acerto
#Com 3 caracteristicas e k = 5  temos aproximadamente 96% de acerto
#Com todas as caracteristicas e k = 5  temos 100% de acerto
